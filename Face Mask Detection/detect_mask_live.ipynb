{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Alarm Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pygame import mixer\n",
    "mixer.init()\n",
    "sound = mixer.Sound('mixkit-security-facility-breach-alarm-994.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_detection_prediction(frame, faceNet, maskNet):\n",
    "\n",
    "    # find the dimension of frame and construct a blob\n",
    "    (h, w) = frame.shape[:2]\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (224, 224),(104.0, 177.0, 123.0))\n",
    "\n",
    "    # pass the blob through the network and obtain the face detections\n",
    "    faceNet.setInput(blob)\n",
    "    detections = faceNet.forward()\n",
    "\n",
    "    # create a empty list which'll store list of faces,face location and prediction\n",
    "    faces = []\n",
    "    locs = []\n",
    "    preds = []\n",
    "\n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        \n",
    "        # find the confidence or probability associated with the detection\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # filter the strong detection [confidence > min confidence(let 0.5)]\n",
    "        if confidence > 0.5:\n",
    "\n",
    "            # find starting and ending coordinates of boundry box\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # make sure bounding boxes fall within the dimensions of the frame\n",
    "            (startX, startY) = (max(0, startX), max(0, startY))\n",
    "            (endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
    "\n",
    "            # extract the face ROI, convert it from BGR to RGB channel\n",
    "            # ordering, resize it to 224x224, and preprocess it\n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "            face = cv2.resize(face, (224, 224))\n",
    "            face = img_to_array(face)\n",
    "            face = preprocess_input(face)\n",
    "\n",
    "            # append the face and bounding boxes to their respective lists\n",
    "            faces.append(face)\n",
    "            locs.append((startX, startY, endX, endY))\n",
    "\n",
    "    # only make a predictions if at least one face was detected\n",
    "    if len(faces) > 0:\n",
    "        # for faster inference we'll make batch predictions on *all*\n",
    "        # faces at the same time rather than one-by-one predictions\n",
    "        # in the above `for` loop\n",
    "        faces = np.array(faces, dtype=\"float32\")\n",
    "        preds = maskNet.predict(faces, batch_size=32)\n",
    "\n",
    "    # return a 2-tuple of the face locations and their corresponding prediction\n",
    "    return (locs, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Caffe Model\n",
    "Caffe (Convolutional Architecture for Fast Feature Embedding) is a deep learning framework that allows users to create image classification and image segmentation models. It is a Caffe model which is based on the Single Shot-Multibox Detector (SSD) and uses ResNet-10 architecture as its backbone. It was introduced post OpenCV 3.3 in its deep neural network module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our serialized face detector model from disk\n",
    "from os.path import dirname, join\n",
    "\n",
    "prototxtPath = join(\"face_detector\", \"deploy.prototxt\")\n",
    "weightsPath = join(\"face_detector\", \"res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "\n",
    "# load the face mask detector model from disk\n",
    "maskNet = load_model(\"fmd_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection on Live Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Alert!!!\n",
      "Normal\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Normal\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Normal\n",
      "Normal\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Normal\n",
      "Alert!!!\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Alert!!!\n",
      "Alert!!!\n",
      "Normal\n",
      "Alert!!!\n"
     ]
    }
   ],
   "source": [
    "# initialize the video stream\n",
    "print(\"[INFO] starting video stream...\")\n",
    "vs = VideoStream(src=0).start()\n",
    "\n",
    "# loop over the frames from the video stream\n",
    "while True:\n",
    "    # grab the frame from the threaded video stream and resize it\n",
    "    # to have a maximum width of 400 pixels\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=400)\n",
    "\n",
    "    # detect faces in the frame and determine if they are wearing a\n",
    "    # face mask or not\n",
    "    (locs, preds) = mask_detection_prediction(frame, faceNet, maskNet)\n",
    "\n",
    "    # loop over the detected face locations and their corresponding\n",
    "    # locations\n",
    "    for (box, pred) in zip(locs, preds):\n",
    "        # unpack the bounding box and predictions\n",
    "        (startX, startY, endX, endY) = box\n",
    "        (mask, withoutMask) = pred\n",
    "        if mask>withoutMask:\n",
    "\n",
    "            label = \"Mask\"\n",
    "            color = (0, 255, 0)\n",
    "            print(\"Normal\")\n",
    "        else:\n",
    "            label = \"No Mask\"\n",
    "            color = (0, 0, 255)\n",
    "            sound.play()\n",
    "            print(\"Alert!!!\")\n",
    "\n",
    "        # include the probability in the label\n",
    "        label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
    "\n",
    "        # display the label and bounding box rectangle on the output frame\n",
    "        cv2.putText(frame, label, (startX, startY - 10),cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
